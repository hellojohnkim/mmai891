{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellojohnkim/mmai891/blob/main/24_891_JohnKim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKmorPdno_n_"
      },
      "source": [
        "# MMAI 891: Individual Assignment\n",
        "\n",
        "Version 1: Updated February 4, 2024\n",
        "\n",
        "<font color='red'>\\# TODO: fill in the below</font>\n",
        "\n",
        "- John Kim\n",
        "- 20439250\n",
        "- MMAI 2024 891\n",
        "- Genius Makers by Cade Metz\n",
        "- Due April 21, 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emfFtv4aHBI1"
      },
      "source": [
        "# Assignment Instructions\n",
        "\n",
        "This assignment contains two (2) questions and one (1) optional question for bonus marks. The questions and parts are wholly contained in this Google Colab Notebook.\n",
        "\n",
        "You are to make a copy of this Notebook and edit the copy to provide your answers/solutions. You are to complete the assignment entirely within Google Colab. Why?\n",
        "\n",
        "- It gives you practice using cloud-based interactive notebook environments (which is a popular workflow)\n",
        "- It is easier for you to manage the environment (e.g., installing packages, etc.)\n",
        "- Google Colab has nice, beefy machines, so you don't have to worry about running out of memory on your local computer.\n",
        "- It will be easier for the TA to help you debug your code if you need help\n",
        "- It will be easier for the TA to mark/run your code\n",
        "\n",
        "## Questions\n",
        "\n",
        "Each question has multiple tasks. There are two types of tasks: tasks that require you to write code and tasks that require you to write text responses.\n",
        "\n",
        "For tasks that require **code**:\n",
        "- Use Python to complete the task.\n",
        "- You may use standard Python libraries, including scikit-learn, pandas,  numpy, transformers, and simpletransformers.\n",
        "- Tips:\n",
        "  - Submit code that runs without errors.\n",
        "  - Submit code that is reproducible. E.g., set random number seeds as appropriate. You should be able to run your code again and again and again, from the top of the file to the bottom of the file, and get the exact same results each time. I should be able to run your code, from scratch, again and again, and get the exact same results that you get.\n",
        "  - Submit code that is organized. Make your code readable. Provide comments to describe what the code is doing and why. Don’t leave “old” code lying around. Overall, if your code is clear and easy to read, then we will be happy. When we are happy, we give better marks.\n",
        "\n",
        "For tasks that require **text responses**:\n",
        "- Type your response in Notebook cell indicated.\n",
        "- Use English. Use proper grammar, spelling, and punctuation. Be professional and clear. Be complete, but not overly verbose.\n",
        "- Feel free to use [Markdown syntax](https://www.markdownguide.org/basic-syntax/) to format your answer (i.e., add bold, italics, lists, tables).\n",
        "- You may refer to your code in your answer. Please do so very clearly. E.g., “As can be seen in on line X above …“\n",
        "\n",
        "\n",
        "## What to Submit to the Course Portal\n",
        "\n",
        "- You are to export your completed Notebook as a PDF file by clicking File->Print->Save as PDF.\n",
        "- Please do not submit the Notebook (.ipynb) file to the course portal.\n",
        "- Please submit the PDF export of the Notebook.\n",
        "   - Please name the PDF file 23_891_FirstnameLastName.pdf\n",
        "      - E.g., *23_891_StephenThomas.pdf*\n",
        "   - Please make sure you have run all the cells so we can see the output!\n",
        "   - Best practice: Before exporting to PDF, click Runtime->Restart and run all.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZFTCX4DqmRO"
      },
      "source": [
        "# Preliminaries: Inspect and Set up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xj34Jz-Do_oK"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqQ_XOKyXTS6",
        "outputId": "c37d4312-b586-4d1a-8670-8a55d21e984f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-02-28 13:48:24.907366\n"
          ]
        }
      ],
      "source": [
        "print(datetime.datetime.now())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfOMt1lErLhZ",
        "outputId": "4e079b0d-56e3-4aac-f0f4-f51814d2ec6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python\n"
          ]
        }
      ],
      "source": [
        "!which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aub2w1-arM5K",
        "outputId": "7cef631a-0150-4054-a04b-901a3a8fadca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Y_n_8UrO9i",
        "outputId": "fa1aef1d-b3bf-4d19-c7ed-af50409d72b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/env/python\n"
          ]
        }
      ],
      "source": [
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qyD7Jl0Gw1E"
      },
      "outputs": [],
      "source": [
        "# TODO: install any packages you need to here. For example:\n",
        "#pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "qckVJuPZ0ebE",
        "outputId": "07323fe2-cdee-48b6-d6e9-27ba0bc0164d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj1NSQelo_oN"
      },
      "source": [
        "# Question 1: Sentiment Analysis via Shallow ML\n",
        "\n",
        "\n",
        "**Marking**\n",
        "\n",
        "The coding parts (i.e., 1.a, 1.b, 1.c4) will be marked based on:\n",
        "\n",
        "- *Correctness*. Code clearly and fully performs the task specified.\n",
        "- *Reproducibility*. Code is fully reproducible. I.e., you (and I) are able to run this Notebook again and again, from top to bottom, and get the same results each time.\n",
        "- *Style*. Code is organized. All parts commented with clear reasoning and rationale. No old code laying around. Code easy to follow.\n",
        "\n",
        "\n",
        "Parts 2 and 3 will be marked on:\n",
        "\n",
        "- *Quality*. Response is well-justified and convincing. Responses uses facts and data where possible.\n",
        "- *Style*. Response uses proper grammar, spelling, and punctuation. Response is clear and professional. Response is complete, but not overly-verbose. Response follows length guidelines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60UNWiX8YmLi",
        "outputId": "a4ea9b49-808a-4567-97c4-39965add94cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2400 entries, 0 to 2399\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  2400 non-null   object\n",
            " 1   Polarity  2400 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 37.6+ KB\n"
          ]
        }
      ],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "# First, we'll read the provided labeled training data\n",
        "df = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1b8MAiN-xBdk6scM-DnufkuijDZivZJqM\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ksKqf_fV6pIO"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "# Next, we'll split it into training and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['Sentence']\n",
        "y = df['Polarity']\n",
        "\n",
        "# So that we can evaluate how well our model is performing, we split our training data\n",
        "# into training and validation.\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R04NzckZKbG2"
      },
      "source": [
        "Lowercase the text:\n",
        "## Part 1.a: Preprocessing and FE Pipeline\n",
        "\n",
        "Clean and preprocess the data (i.e., `X_train`) as you see necessary. Extract features from the text (i.e., vectorization using BOW and/or Bag of N-Grams and/or topics and/or lexical features).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Qeavkicwo_oN"
      },
      "outputs": [],
      "source": [
        "# Define the vectorizer\n",
        "vectorizer = None\n",
        "\n",
        "# Lowercase the text:\n",
        "X_train = X_train.str.lower()\n",
        "\n",
        "# Remove punctuation\n",
        "X_train = X_train.apply(lambda x: ''.join([char for char in x if char not in string.punctuation]))\n",
        "\n",
        "# Remove stop words:\n",
        "stop = stopwords.words('english')\n",
        "X_train = X_train.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "\n",
        "# Feature Extraction\n",
        "\n",
        "# Bag of Words\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Bag of N-Grams\n",
        "vectorizer = CountVectorizer(ngram_range=(2, 3))\n",
        "X_train_ngrams = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Topics\n",
        "# Latent Dirichlet Allocation (LDA)\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "lda = LatentDirichletAllocation(n_components=10)\n",
        "X_train_topics = lda.fit_transform(X_train_tfidf)\n",
        "\n",
        "# Lexical Features\n",
        "# TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Combine features\n",
        "X_train_topics_flattened = X_train_topics.ravel()\n",
        "X_train_combined = np.hstack((X_train_bow, X_train_ngrams, X_train_topics_flattened, X_train_tfidf))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train_bow.shape: {X_train_bow.shape}\")\n",
        "print(f\"X_train_ngrams.shape: {X_train_ngrams.shape}\")\n",
        "print(f\"X_train_topics.shape: {X_train_topics.shape}\")\n",
        "print(f\"X_train_tfidf.shape: {X_train_tfidf.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBLUKjYX2KRd",
        "outputId": "28cde65d-ae68-40da-c6e5-cf6db08c7366"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_bow.shape: (1800, 3376)\n",
            "X_train_ngrams.shape: (1800, 14551)\n",
            "X_train_topics.shape: (1800, 10)\n",
            "X_train_tfidf.shape: (1800, 3376)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train_combined.shape: {X_train_combined.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9bkAWtI2y2s",
        "outputId": "bb6a5564-8a90-4d85-c16a-0038fb213059"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_combined.shape: (18003,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train_bow.shape: {X_train_bow.shape}\")\n",
        "print(f\"X_train_ngrams.shape: {X_train_ngrams.shape}\")\n",
        "print(f\"X_train_topics.shape: {X_train_topics.shape}\")\n",
        "print(f\"X_train_tfidf.shape: {X_train_tfidf.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28cde65d-ae68-40da-c6e5-cf6db08c7366",
        "id": "9xU01L0qb2wB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_bow.shape: (1800, 3376)\n",
            "X_train_ngrams.shape: (1800, 14551)\n",
            "X_train_topics.shape: (1800, 10)\n",
            "X_train_tfidf.shape: (1800, 3376)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train_combined.shape: {X_train_combined.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6a5564-8a90-4d85-c16a-0038fb213059",
        "id": "gLIioVKwb2wM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_combined.shape: (18003,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7FIkMnao_oO"
      },
      "source": [
        "## Part 1.b: Model Training/Tuning/Cross Validation\n",
        "\n",
        "Use your favorite shallow ML algorithm (such as decision trees, KNN, random forest, boosting variants) to train a classification model.  Don’t forget everything we’ve learned in the machine learning course: hyperparameter tuning, cross-validation, handling imbalanced data, etc. Make reasonable decisions and try to create the best-performing model that you can.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgek8ghwo_oP"
      },
      "outputs": [],
      "source": [
        "# TODO: insert code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjUgRW1N6ppS"
      },
      "source": [
        "## Part 1.c: Model Assessment\n",
        "\n",
        "Use your model to predict the sentiment of the testing data. Measure the performance (e.g., accuracy, AUC, F1-score) of your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYlrWng9MqmL",
        "outputId": "e4c6a0f2-2150-4458-9d0b-df3e6a0675d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 600 entries, 0 to 599\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Sentence  600 non-null    object\n",
            " 1   Polarity  600 non-null    int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 9.5+ KB\n"
          ]
        }
      ],
      "source": [
        "# DO NOT MODIFY THIS CELL\n",
        "\n",
        "test_df = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1taoTluPBUMt9JkKAnlqDTrU49DJFpJGW\")\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMm6r-wSOUY1"
      },
      "outputs": [],
      "source": [
        "# TODO: insert code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wUBcyrdM3__"
      },
      "source": [
        "## Part 2: Given the performance of your model, are you satisfied with the results? Explain.\n",
        "\n",
        "Keep your response to 1000 characters or less."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oCr-mTfNG-H"
      },
      "source": [
        "TODO: Insert answer here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz8dTvnJNKLL"
      },
      "source": [
        "## Part 3: Show five test instances in which your model was incorrect. Dive deep and find out why your model was wrong.\n",
        "\n",
        "Keep your response to 1000 characters or less."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DekZ7mulNTmr"
      },
      "source": [
        "TODO: Insert answer here. (Feel free to create new code cells if necessary.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2nBXXwBQaFk"
      },
      "source": [
        "# Question 2: Conceptual Understanding of the SOTA\n",
        "\n",
        "\n",
        "**Marking**\n",
        "\n",
        "The following questions will be marked on:\n",
        "\n",
        "- *Quality*. Response is well-justified and convincing. Responses uses facts and data where possible.\n",
        "- *Style*. Response uses proper grammar, spelling, and punctuation. Response is clear and professional. Response is complete, but not overly-verbose. Response follows length guidelines.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hmLwD6-Qs3U"
      },
      "source": [
        "## Part 1: What is transfer learning and fine-tuning in NLP? What advantages does it have over training from scratch?\n",
        "\n",
        "Keep your response to 1000 characters or less."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcXqPprFQyUM"
      },
      "source": [
        "TODO: Insert answer here. (Feel free to create new code cells if necessary.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oorJvilBQ2g1"
      },
      "source": [
        "## Part 2: What is a Large Language Model (LLM) and what are their strengths and weaknesses?\n",
        "\n",
        "Keep your response to 1000 characters or less."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNQn5LYaQ5qH"
      },
      "source": [
        "TODO: Insert answer here. (Feel free to create new code cells if necessary.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE2GL8VMNKHj"
      },
      "source": [
        "# Question 3 (Optional/Bonus): Sentiment Analysis via Deep ML\n",
        "\n",
        "This question is optional and is worth up to 5 extra credit marks.\n",
        "\n",
        "Use deep learning (e.g., RNNs and variants, CNNs and variants, and/or transformers) to build a model on the same dataset as Q1 and compare the results with the Shallow ML model.\n",
        "\n",
        "You may train your own deep ML model (using, e.g., the keras library) or fine-tune a pretrained deep ML model (using, e.g., the transformers library and the Huggingface ecoystem)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhM3_13LRdTI"
      },
      "outputs": [],
      "source": [
        "# TODO: Insert code here."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}